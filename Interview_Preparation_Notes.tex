\documentclass[12pt]{amsart}
\usepackage{amsmath,amssymb,amscd,amsthm,mathtools,verbatim,geometry}
\numberwithin{equation}{section}
\newcommand{\al}{\alpha}
\newcommand{\be}{\beta}
\newcommand{\de}{\delta}
\newcommand{\ep}{\varepsilon}

%\newcommand*{\longhookrightarrow}{\ensuremath{\lhook\joinrel\relbar\joinrel\rightarrow}}

\newcommand{\A}[1]{\mathcal{A}_{#1}}
\newcommand{\M}[1]{\mathcal{M}_{#1}}
\newcommand{\CA}[1]{\overline{\mathcal{A}}_{#1}}
\newcommand{\CM}[1]{\overline{\mathcal{M}}_{#1}}
\newcommand{\RA}[1]{\mathcal{RA}_{#1}}



\renewcommand{\Im}{{\operatorname{Im}\,}}
\renewcommand{\Re}{{\operatorname{Re}\,}}
\newcommand{\ord}{\operatorname{ord}\nolimits}
\newcommand{\CC}{{\mathbb{C}}}
\newcommand{\GG}{{\mathbb{G}}}
\newcommand{\HH}{{\mathbb{H}}}
\newcommand{\FF}{{\mathbb{F}}}
\newcommand{\EE}{{\mathbb{E}}}
\newcommand{\KK}{{\mathbb{K}}}
\newcommand{\PP}{{\mathbb{P}}}
\newcommand{\QQ}{{\mathbb{Q}}}
\newcommand{\RR}{{\mathbb{R}}}
\newcommand{\ZZ}{{\mathbb{Z}}}
\newcommand{\SSS}{{\mathbb{S}}}
\newcommand{\MM}{{\mathbb{M}}}
\newcommand{\NN}{{\mathbb{N}}}
\newcommand{\DD}{{\mathbb{D}}}
\newcommand{\VV}{{\mathbb{V}}}
\newcommand{\calO}{{\mathcal O}}
\newcommand{\calH}{{\mathcal H}}
\newcommand{\calT}{{\mathcal T}}
\newcommand{\calF}{{\mathcal F}}
\newcommand{\calI}{{\mathcal I}}
\newcommand{\calA}{{\mathcal A}}
\newcommand{\calC}{{\mathcal C}}
\newcommand{\calK}{{\mathcal K}}
\newcommand{\calL}{{\mathcal L}}
\newcommand{\calM}{{\mathcal M}}
\newcommand{\calN}{{\mathcal N}}
\newcommand{\calJ}{{\mathcal J}}
\newcommand{\calP}{{\mathcal P}}
\newcommand{\calE}{{\mathcal E}}
\newcommand{\calG}{{\mathcal G}}
\newcommand{\calW}{{\mathcal W}}
\newcommand{\calX}{{\mathcal X}}
\newcommand{\calY}{{\mathcal Y}}
\newcommand{\calD}{{\mathcal D}}
\newcommand{\calR}{{\mathcal R}}
\newcommand{\calS}{{\mathcal S}}
\newcommand{\bK}{{\textbf K}}
\newcommand{\bw}{{\boldsymbol\omega}}
\newcommand{\tK}{{\widetilde{K}}}
\newcommand{\tw}{{\widetilde{\omega}}}
\newcommand{\tbK}{{\widetilde{\textbf K}}}
\newcommand{\tbw}{{\widetilde{\boldsymbol\omega}}}
\newcommand{\txi}{{\tilde{\xi}}}
\newcommand{\teta}{{\tilde{\eta}}}
\newcommand{\tXi}{{\widetilde{\Xi}}}
\newcommand{\hXi}{{\widehat{\Xi}}}
\newcommand{\hC}{{\widehat{C}}}
\newcommand{\tbC}{{\widetilde{C}}}

\newcommand{\op}{\operatorname}
\newcommand{\Sp}{\op{Sp}}
\newcommand{\PSp}{\op{PSp}}
\newcommand{\GSp}{\op{GSp}}
\newcommand{\GL}{\op{GL}}
\newcommand{\SL}{\op{SL}}
\newcommand{\Mat}{\op{Mat}}
\newcommand{\Sym}{\op{Sym}}
\newcommand{\Sing}{\op{Sing}}
\newcommand{\symm}{\op{symm}}
\newcommand{\tor}{\op{tor}}
\newcommand{\CH}{\op{CH}}
\newcommand{\NS}{\op{NS}}
\newcommand{\Pic}{\op{Pic}}
\newcommand{\NSQ}{\op{NS}_{\mathbb Q}}
\newcommand{\even}{\op{even}}
\newcommand{\odd}{\op{odd}}
\newcommand{\hol}{\op{hol}}
\newcommand{\res}{\op{res}}
\newcommand{\End}{\op{End}}
\newcommand{\Jac}{\op{Jac}}

\newcommand\diag{\operatorname{diag}}
\newcommand\tr{{\rm tr}}
\newcommand\codim{{\rm codim}}
\newcommand\rank{\operatorname{rank}}
\newcommand\Res{\operatorname{Res}}
\newcommand\us{{\underline{s}}}
\newcommand\uu{{u}}
\newcommand\urho{{\underline{\rho}}}
\newcommand\usigma{{\underline{\sigma}}}
\newcommand\oC{{C_\us}}
\newcommand\tC{{\widetilde{C}}}
\newcommand\wtK{{\widetilde{K}}}
\newcommand\uv{{\underline{v}}}
\newcommand\uE{{\underline{{\mathcal E}}}}
\newcommand\uc{{\underline{c}}}
\newcommand\uw{\underline{w}}
\newcommand\ut{{\underline{t}}}
\newcommand\ux{{\underline{x}}}
\newcommand\uy{{\underline{y}}}
\newcommand\uz{{\underline{z}}}
\newcommand\um{{\underline{m}}}
\newcommand\uR{{\underline{R}}}
\newcommand\ur{{\underline{r}}}
\newcommand\uf{{\underline{f}}}
\newcommand\uh{{\underline{h}}}
\newcommand\ug{{\underline{g}}}
\newcommand\uk{{\underline{k}}}
\newcommand\ulambda{{\underline{\lambda}}}
\newcommand\uphi{{\underline{\phi}}}
\newcommand\uPhi{{\underline{\Phi}}}
\newcommand{\upsi}{\underline{\psi}}
\newcommand{\ueta}{\underline{\eta}}
\newcommand{\ugamma}{\underline{\gamma}}
\newcommand\PS[1][N-1]{{\SSS_+^{#1}}}
%\newcommand\PJP{parametric jump problem\xspace}

%shorthand

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lm}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{fact}[thm]{Fact}
\newtheorem{qu}[thm]{Question}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{summary}[thm]{Summary}
\newtheorem{prob}[thm]{Problem}

\theoremstyle{definition}
\newtheorem{df}[thm]{Definition}
%\newtheorem{df-cons}[thm]{Definition-construction}
\newtheorem{notat}[thm]{Notation}
\newtheorem{rmk}[thm]{Remark}
\newtheorem{exa}[thm]{Example}

\newenvironment{aside}{\begin{quote}\sffamily}{\end{quote}}

\newcommand{\Xuntao}[1]{\begin{aside}{Xuntao: #1}\end{aside}}

\usepackage[notcite,notref]{showkeys}

\begin{document}
\title{Data Science Interview\\Preparation Notes}
\author{Xuntao Hu}
\address{Mathematics Department, Stony Brook University,
Stony Brook, NY 11794-3651, USA}
\email{}

\maketitle
\tableofcontents

This note is the official write-up of my personal notes for preparing for interviews for Data Scientist positions. 

Remember that this note is not self-contained (yet), therefore it may not fit perfectly into your knowledge system. There are some concepts I missed out, for instance Bayesian Formula, Cross Validation, etc. This note will be beneficial to the reader who already has built the knowledge system of statistics, machine learning, and are looking for a quick summary and review before the interviews.

%-------------------------------------------------------------------------------------------------------------------------------
%-----------------------------------------------------------Statistics--------------------------------------------------------
%-------------------------------------------------------------------------------------------------------------------------------

\section{Statistics}

To prepare for stats questions I used the book \cite{SI}.

\subsection{Basics Concepts}
\subsubsection{Density functions.}
\begin{enumerate}
\item Cumulative Distribution Function (cdf): $F_X(x):= P(X\leq x)$, the probability of a random variable $X$ taking a value less of equal to $x$.
\item Probability Density Function (pdf): $f_X(x) = \frac{d}{dx}F_X(x)$.
\item Expectation: $Eg(x) = \int_{-\infty}^\infty g(t)f_X(t)dt$.
\item Variance: $Var(X) = E(X-EX)^2 = E(X^2-2X*EX+EX^2)=EX^2-(EX)^2$
\end{enumerate}
We also see 
$$F_X(x) = \int_{-\infty}^xf_X(t)dt.$$ 
Or in particular, 
$$P(a\leq X \leq b)=F_X(b)-F_X(a)=\int_a^bf_X(t)dt.$$

\subsubsection{Change of variable} if $Y=g(X)$:
$$
F_Y(y) = P(Y\leq y) = P(g(X)\leq y).
$$
From here: if $g$ increasing, then $P(g(X)\leq y) = P(X\leq g^{-1}(y))=F_X(g^{-1}(y))$; if $g$ decreasing, then $P(g(X)\leq y) = 1-P(X\leq g^{-1}(y))=1-F_X(g^{-1}(y)$.

\subsubsection{Expectation and Variance of Sums}, if $X_1,\ldots, X_n$ iid,
$$
E(\sum g(X_i)) = nEg(X_i)
$$
$$
Var(\sum g{X_i})=nVar(g(X_i))
$$

\subsection{Common Families of Distributions}
\subsubsection{Discrete Distributions}
\begin{enumerate}
\item Discrete Uniform Distribution: 
\begin{itemize}
\item pmf: $P(X=x|N) = 1/N$ when $x=1,\ldots, N$
\end{itemize}

\item Bernoulli Distribution:
\begin{itemize}
\item pmf: Given $0\leq p\leq 1$, $P(x=1)=p$, and $P(x=0)=1-p$
\item $EX=p$, 
\item $Var(X) = E(E-EX)^2 = (1-p)^2p+(0-p)^2(1-p)=p(1-p)$
\end{itemize}

\item Binomial Distribution:
\begin{itemize}
\item pmf: $P(X=x|n,p) = {{n} \choose {x}}p^x(1-p)^{n-x}$.
\item This gives the probability of exactly $x$ success in $n$ trial when the outcome of each trial is iid Bernoulli(p).
\item $EX= np$, $VarX = np(1-p)$.
\item If $X_1,\ldots, X_n\sim bernoulli(p)$ iid, then $\sum X_i\sim binomial(n,p)$.
\end{itemize}


\item Poisson Distribution:
\begin{itemize}
\item pmf: $P(X=x|\lambda) = \frac{e^{-\lambda}\lambda^x}{x!}$
\item $EX = Var(X) = \lambda$
\item Given $\lambda$, the expected number of occurrence of an event in a given period (e.g. a minute), $P(X=x|\lambda)$ gives the possibility of the event occur $x$ times in the next period.
\end{itemize}

\item Negative Binomial Distribution:
\begin{itemize}
\item pmf: $P(X=x|r,p) = {{x-1}\choose{r-1}}p^r(1-p)^{x-r}$
\item Number of trials until the $r$-th success, while each trial is a binomial variable with prob $p$.
\end{itemize}

\item Geometric Distribution:
\begin{itemize}
\item pmf: $P(X=x|p) = p(1-p)^{x-1}$
\item Number of trials until the first success. Special case of Negative Binomial Distribution when $r=1$.
\end{itemize}
\end{enumerate}

\subsubsection{Continuous Distributions}
\begin{enumerate}

\item Uniform Distribution:
\begin{itemize}
\item pdf: $f(x|a,b)=1/(b-a)$ if $a\leq x\leq b$ else 0.
\item $EX = (a+b)/2$, $Var(X) = \frac{b^3-a^3}{3(b-a)}-(\frac{a+b}{2})^2$
\end{itemize}

\item Normal DIstribution:
\begin{itemize}
\item pdf: $f(x|\mu,\sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}exp(-\frac{(x-\mu)^2}{2\sigma^2})$
\item $EX = \mu$, $VarX = \sigma^2$
\end{itemize}

\item Gamma Distribution:
\begin{itemize}
\item pdf: $f(t|\alpha) = \frac{t^{\alpha-1}e^{-t}}{\Gamma(\alpha)}$, where $\Gamma(\alpha) = \int_0^\infty t^{\alpha-1}e^{-t}dt$.
\item change $x=\beta t$: $f(x|\alpha, \beta)=\frac{x^{\alpha-1}e^{-x/\beta}}{\Gamma(\alpha)\beta^\alpha}$.
\item $EX=\alpha\beta$, $VarX=\alpha\beta^2$
\end{itemize}

\item $\chi^2$ Distribution with $p$ degree of freedom:
\begin{itemize}
\item pdf: $f(x|p)=\frac{x^{p/2-1}e^{x/2}}{\Gamma(p/2)2^{p/2}}$. This is Gamma Distribution with $\alpha = p/2, \beta = 2.$
\item $EX = p$, $VarX = 2p$.
\end{itemize}

\item Exponential Distribution:
\begin{itemize}
\item pdf: $f(x|\beta)=\frac{1}{\beta}e^{-x/\beta}$. This is Gamma Distribution with $\alpha = 1$
\item When sampling $X_1,\ldots, X_n\sim exp(\beta)$ iid, we have $\sum X_i \sim Gamma(n,\beta)$.
\end{itemize}
\end{enumerate}

\subsection{Multi-variable Distributions}
Joint cumulative distribution function $F_{X,Y}(x,y) = P(X\leq x, Y\leq y)$. Joint pdf $f_{X,Y}(x,y) = \frac{\partial^2F_{X,Y}}{\partial x\partial y}$.


Given a joint distribution $f_{X,Y}(x,y)$, find the pdf for $Z=g(X,Y)$:
$$
F_Z(z) = P(Z\leq z) = P(g(X,Y)<z)=\int_{g(X,Y)<z}f_{X,Y}(x,y)dxdy
$$

\subsubsection{Conditional Probability.}

Marginal density function: $f_X(x) = \int_{-\infty}^{\infty}f_{X,Y}(x,y)dy$. (Similarly for $f_Y(y)$). The conditional pdf is given by
$$
f(x|y) = \frac{f_{X,Y}(x,y)}{f_X(x)}
$$
If two variables are independent: $f_{X,Y}(x,y)=f_X(x)f_Y(y)$.

\subsubsection{Bivariate Transformations}. Given variable change: $X,Y\to U = g_1(X,Y), V=g_2(X,Y)$, then 
$$
f_{U,V}(u,v) = \sum_{X,Y\in A_{U,V}}f_{X,Y}(x,y)
$$
If the transformation is invertible, namely we can write $X = h_1(U,V), Y = h_2(U,V)$, then
$$
f_{U,V}(u,v) = f_{X,Y}(x,y)|Jac(h_1,h_2)|
$$.
Note: sometimes only $U = g(X,Y)$ is given, we can find some $V=g_2(X,Y)$, so that we can compute $f_{U,V}$, and further find the marginal pdf $f_U$.

\subsubsection{Useful Cases} 
\begin{itemize}
\item Sum: $P(X+Y<c)$:
$$
F(X+Y) = P(X+Y<c) = \int_{-\infty}^{infty}(\int_{-\infty}^{c-y}f_{X,Y}(x,y)dx)dy
$$
\item Max: Given $(X_i)_{i = 1,\ldots, n}$ iid. 
$$F_{max}(x) = P(\max X_i<x) = P(X_1<x, \ldots, X_n<x) = \prod P(X_i<x)=F^n(x)$$
\item Min: Given $(X_i)_{i = 1,\ldots, n}$ iid. 
$$
F_{min}(x) = P(\min X_i<x) = 1-P(\min X_i > x) = 1-\prod P(X_i>x) = 1-(1-F(x))^n
$$
\end{itemize}

\subsubsection{Expectation, Covariance, Correlation}
$$Eg(X,Y)=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}g(x,y)f_{X,Y}(x,y)dxdy$$

$$Cov(X,Y) = E((X-EX)(Y-EY))=E(X,Y)-EXEY$$

$$
\rho_{X,Y}= \frac{Cov(X,Y)}{\sqrt{Var(X)Var{Y}}}
$$
If $X, Y$ are independent:
$$
E(X,Y) = \int xyf(x,y) = \int xyf_X(x)f_Y(y) = \int xf_X\int yf_Y = EXEY
$$
$$
Cov(X,Y) = 0
$$

Covariance is linear in both variables.

\subsection{Estimators}

\subsection{Sampling}
Assume $X_1,\ldots, X_n$ are iid variables and have $n(\mu, \sigma^2)$ distribution. We then know two quantities:
$$
E\bar{X} = \mu, \qquad Var\bar{X} = \frac{\sigma^2}{n}
$$

We will have our discussion in two cases: whether the standard variation $\sigma$ is known or unknown.
\subsubsection{$\sigma$ known}
In this case 
$\bar{X}\sim n(\mu, \sigma^2/n)$, so $\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\sim n(0,1)$.

\subsubsection{$\sigma$ unknown} 
This is a trickier case. We first need to estimate $\sigma$ using the samples.

An estimate of $\mu$ is $\bar{X}$, as seen above. So we can define
$$
S^2 = \frac{1}{n-1}\sum(X_i-\bar{X})^2
$$ 
Note that the $n-1$ in the denominator is essential, due to the following fact
\begin{equation}
\begin{split}
(n-1)ES^2 &= E(\sum(X_i-\bar{X})^2)\\
&=\sum E(X_i-\mu)^2-nE(\bar{X}-\mu)^2 \\
& =\sum Var(X_i) - nVar\bar{X}\\
&=(n-1)\sigma^2
\end{split}
\end{equation}
Therefore $ES^2=\sigma^2$, so $S^2$ is an unbiased estimator of the variance.

We can then consider the distribution of the quantity $\frac{\bar{X}-\mu}{S/\sqrt{n}}$. Note that it is not a normal distribution. Since 
$
\frac{(n-1)S^2}{\sigma^2}\sim \chi^2_{n-1},
$
we can compute the pdf of
$$
\frac{\bar{X}-\mu}{S/\sqrt{n}} = \frac{\bar{X}-\mu}{\sigma/\sqrt{n}}/\sqrt{\frac{S^2}{\sigma^2}}
$$
where we know the numerator has a $n(0,1)$ distribution and the square of the denominator has a $\chi^2_{n-1}/(n-1)$ distribution. The pdf of the above variable is
$$
f(t) = \frac{\Gamma((p+1)/2)}{\sqrt{2\pi p}\Gamma(p/2)2^{p/2}}(\frac{2}{1+t/p})^{(p+1)/2}
$$
This distribution is called {\em Student's t-distribution}.

\subsection{Hypothesis Testing}
\subsubsection{Confidence Interval}
The confidence interval is a range of values that the target value is likely (with certain probability) to fall into. There are two ways to find a ($95\%$) confidence interval;
\begin{enumerate}
\item Use boostraping to get a large number ($k$) of training sets, do experiments on these sets and get $k$ values of the desired quantity. Sort them from small to large, then take the middle 95\% of the values.
\item The confidence interval can be found using the sample mean, the standard variation and the sample size.
\end{enumerate}
\subsubsection{p-value}
The p-value is used in determining statistical significance in a hypothesis test. The value evaluates the probability that we will make a mistake if we reject the null hypothesis (false positive). We will want small p-value, and the usual threshold is $p=0.05$.

\subsubsection{z-test} If we have samples set $\{x_i\}$, and we know that the set follows a normal distribution with known variance $\sigma^2$ and unknown mean. We want to test if the mean of the set $\bar x$ is significant different to a given value $\mu_0$. We can use the z-test. Compute the following z-value:
$$
z = \frac{\bar x-\mu_0}{\sigma\sqrt{n}}
$$
Our null hypothesis is that $H_0$: the set does not show a significant difference to a $n(\mu_0,\sigma^2)$ distribution. Under this hypothesis, $z\sim n(0,1)$. Therefore if our actual data gives us a $z>z_{n,\alpha/2}$ where $\alpha$ is usually taken to be $0.05 = 5\%$. That is to say:
$$
z = \frac{\bar x-\mu_0}{\sigma\sqrt{n}}>z_{n,\alpha/2}.
$$
Then it means that there is less than $5\%$ of chance that this scenario would happen, but it does happen. Therefore we have $95\%$ of confidence to reject the null hypothesis and to state that the mean of the sample set is different from $\mu_0$.

Another way to look at this is via the confidence interval. The 95\% confidence interval of the population mean is 
$$
[\bar x-z_{n,\alpha/2}*\sigma/\sqrt{n}, \qquad\bar x+z_{n,\alpha/2}\sigma\sqrt{n}].
$$
This means we have 95\% of confidence that the true value of our mean falls into this interval. And if $\mu_0$ does NOT fall into this interval, that means we have 95\% of confidence that $\mu_0$ is not our true value of sample mean.

We also want to mention the relationship to the p-value here: the discussion above compares the calculated $z$ to $z_{n,\alpha/2}$. We found $z_{n,\alpha_2}$ via the normal distribution table. We can also find the corresponding $\alpha$ value of our calculated $z$. This is the probability of rejecting the null hypothesis and made a mistake, so the $\alpha$ value here is in fact our p-value.

\subsubsection{Example - Coin Flipping}

We want to discuss a most basic example of the z-test, which is also the most commonly seen interview question on the A/B testing. 

We have a coin. We want to test if the coin is fair by continuously flipping it and record how many heads and how many tails we will get. Assume we flip the coin $n$ times and get $k$ heads. Let $\hat p = k/n$. Naturally, the null hypothesis here is $H_0: \hat p = 0.5$.

IMPORTANT NOTE: it is very easy to confuse about the "experiment" we run here. We don't view the whole event as one experiment. Instead, we view each flip as an experiment. We can view the result of each flip as an independent Bernoulli variable, which either gets head with probability $p$, or gets tail with probability $(1-p)$. Here $p=0.5$, but we can of course use other values, depending on what we want to test.

Now suppose the null hypothesis holds, then the mean of the set of Bernoulli trials is equal to $p$. Note that this is a binomial variable. We would also like to know the variance of the Bernoulli experiments - as in Section 2 we know that it has variance $p(1-p)/n$.

It is very important to know that when the number of trials is large, we can approximate this quantity using normal distribution (the Central Limit Theorem). Since in this case the variance is known, we can run the z-test with the following z-value
$$
z = \frac{\hat p-p}{\sqrt{p(1-p)/n}}
$$
Therefore if we have $z>z_{n,\alpha/2}$, we can reject the null hypothesis and say that the new version of the ad does make a difference.

Furthermore, we can compute the confidence interval for the result:
$$
[\hat p-z_{n,\alpha/2}\sqrt{p(1-p)/n}, \qquad \hat p+z_{n,\alpha/2}\sqrt{p(1-p)/n}]
$$
This means we have $(1-\alpha)$ confidence that the true probability of getting the head lies in this interval. If $p=0.5$ does not lie in this interval, that means it is different to the true value, and hence the coin is not fair.

\subsubsection{One sample t-test}

If we have samples set $\{x_i\}$, and we know that the set follows a normal distribution with unknown variance and unknown mean. We want to test if the mean of the set $\bar x$ is significant different to a given value $\mu_0$. Note the difference to the z-test here is that the variance is unknown. Hence we will need to use the estimator of the variance, as discussed above.

Let $S = \frac{\sum (x_i-\bar x)^2}{n-1}$, the unbiased estimator of $\sigma^2$. Then the t-stats to test $H_0: \bar x=\mu_0$ is:
$$
t = \frac{|\bar x-\mu_0|}{s/\sqrt{n}}.
$$
From here on it is the standard procedure: we can either A) read the table and find $t_{n-1,\alpha/2}$ and if $t>t_{n-1,\alpha/2}$ the we reject $H_0$; or B) read the table and find the corresponding p-value of the $t$, and compare the p-value with the threshold $\alpha$ (normally $0.05$), if $p<\alpha/2$, then we reject $H_0$.

\subsubsection{Two sample t-test}
This is perhaps the most common A/B testing scenario. The two sample t-test is to test whether two populations are significantly different from one another.

If the two sets of data are {\bf paired}: then we can just use one sample t-test on the differences of the paired samples and $\mu_0 = 0$.

If the two sets of data are {\bf unpaired}: that means assuming the two populations are independent (most common cases). In this case we want to test $H_0:$ the means of the two populations are equal.

If we assume {\bf equal variance}, then we should look at 
$$
t = \frac{\bar x_1-\bar x_2}{\sqrt{s^2(\frac{1}{n_1}+\frac{1}{n_2})}}.
$$
If we assume {\bf unequal variance}, then we should look at 
$$
t = \frac{\bar x_1-\bar x_2}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}
$$
In both cases the degree of freedom is $(n_1-1)+(n_2-1)$.

\subsubsection{Example: Click Through Rate (CTR)}

Consider the scenario that we have two ads (or maybe two version of a website), we want to test whether they will introduce a significant difference. We collected $n_1$ users who have viewed the new version of the ad. Inside the $n_1$ users we have $k_1$ users who click on the ad. We also have a reference group of $n_2$ users in which $k_2$ clicked on the on the old version of the ad. Now we have click through rates (CTR) for the two groups $\hat p_1 = k_1/n_1$ and $\hat p_2 = k_2/n_2$.

IMPORTANT NOTICE: We now want to test whether the {\em true values} $p_1, p_2$ of the CTR of the two version is the same. The problem is that we don't know the true values. We can only use the results of the experiment $\hat p_1$ and $\hat p_2$ to estimate the true values $p_1$ and $p_2$.

As before, under the null hypothesis, we can assume that the results both limit to normal distributions. Then we have
$$
\hat p_1 \sim n(p_1,p_1(1-p_1)/n_1)
$$
$$
\hat p_2 \sim n(p_2,p_2(1-p_2)/n_2)
$$
We can deduce that
$$
\hat p_1 - \hat p_2 \sim n(p_1-p_2, \frac{p_1(1-p_1)}{n_1}+\frac{p_2(1-p_2)}{n_2})
$$
where in fact we will plug $\hat p_1$ into $p_1$ and $\hat p_2$ into $p_2$, and compute the following t-stats:
$$
t = \frac{|\hat p_1-\hat p_2|}{\sqrt{\frac{p_1(1-p_1)}{n_1}+\frac{p_2(1-p_2)}{n_2}}}.
$$
The degree of freedom is $n_1+n_2-2$. As long as $t>t_{n_1+n_2-2, \alpha/2}$, we can reject the null hypothesis and declare that the two versions make a difference.

\subsubsection{$\chi^2$ test}
%-------------------------------------------------------------------------------------------------------------------------------
%----------------------------------------------------Machine Learning---------------------------------------------------
%-------------------------------------------------------------------------------------------------------------------------------
\section{Machine Learning}

I used the book \cite{ISLR} to prepare for Machine Learning models.

\subsection{Linear Regression}

Supervised Learning. All discussion here is for simple linear regression, namely the predictor is 1-dim. Given data points $(x_i, y_i)$ where $i = 1,\ldots, n$, where $n$ is the number of the input data.

For a model whose linear function is $\hat y = a+bx$. The {\em cost function} of the linear model is the Residual Sum of Squares: $$RSS = \sum_1^n(y_i-(a+bx_i))^2.$$
We want the "best" $a, b$ such that RSS is minimized.

Taking $\frac{dRSS}{da}=0$, we can deduce $a=\bar{y}-b\bar{x}$.

Taking $\frac{dRSS}{db}=0$, we can get 
$$
b=\frac{\sum(x_i-\bar{x})(y_i-\bar{y})}{\sum(x_i-\bar{x})}=\frac{S_{xy}}{S_{xx}}
$$
Assuming all $y_i$ is iid and have variance $\sigma^2$, we can compute
$$
Var(a) = \sigma^2\frac{\sum x_i^2}{nS_{xx}}, \qquad Var(b)=\frac{\sigma^2}{S_{xx}}
$$
We then know that $b\sim n(\frac{S_{xy}}{S_{xx}},\frac{\sigma^2}{S_{xx}})$ and $a\sim n(\bar{y}-b\bar{x},\sigma^2\frac{\sum x_i^2}{nS_{xx}},)$.

We often don't know the variance of $y_i$, therefore we need an estimator for that. MLE of $\sigma^2$ is called Residual Squared Error:
$$
S^2:= RSE^2 = RSS/(n-2)
$$
Then the MLE for $Var(b)=\sigma^2/S_{xx}$ is $S^2/S_{xx}$. So we can use $t-test$ for the null hypothesis $b = 0$:
$$
t = \frac{b-0}{\sqrt{s^2/S_{xx}}} \sim t_{n-2}
$$
To reject $b=0$, we only need $|t|>t_{n-2,\alpha/2}$.

\subsubsection{Important Stats}
The R-Squared stats is computed using $TSS=\sum(y_i-\bar y)$ and $RSS=\sum(y_i - \hat y_i)$:
$$
R^2=\frac{TSS-RSS}{TSS}
$$
It is the portion of the variance explained by the linear model. Interesting fact: 
$R = Cor(X,Y)=\frac{S_{xy}}{\sqrt{S_{xx}S_{yy}}}$ is the square root of $R^2$. This makes sense since both quantities measures the the level of linearity among the data points.

More General Case: F-stats will be used when the number of predictor is $p$
$$
F = \frac{(TSS-RSS)/p}{RSS/(n-p-1)}
$$
R-square is the same as the F-stats when $p=1$.

IMPORTANT NOTE: Both R-Square and F stats can only be used on measuring the level of linearity on the training data. We need to use other measurements such as MSE (mean squared error), or the above mentioned $RSS$ for test error.

\subsubsection{Lasso and Ridge}
The idea on Lasso and Ridge is to add a punishment on the cost function. 

Lasso: $\lambda\sum |b_i|$ - L1 norm of the coeffients

Ridge: $\lambda\sum b_i^2$ - L2 norm of the coeffients

One big and essential difference is that Lasso can introduce sparsity into the coefficients. Namely some of the coefficients will become zero. Therefore Lasso is automatically selecting features for us. 

However, the purpose of feature selection is to reduce collinearity among the features. Ridge can also have a similar effect. For instance is $x_1 = 2x_2$, then we will get $b_1 = 1/2*b_2$. In usual linear model both $b_1$ and $b_2$ are significant. But when we apply the punish terms, $b_1$ will drop to zero much faster than $b_2$. In Lasso it might directly become 0.

\subsection{Logistic Regression}

Sigmoid function: $$f(x)=\frac{1}{1+e^x}$$ This function takes value between $0$ and $1$ (S-shape).

Basic idea of logistic regression is to use the Sigmoid function to estimate the probability of $Y=1$ or $Y=0$ given $x$. The formulation is basically a linear model composite with the sigmoid function:
$$
P(Y=0|X)=\frac{1}{1+e^{a+bx}},\qquad P(X):=P(Y=1|X)=\frac{e^{a+bx}}{1+e^{a+bx}}
$$
Or to write in another way:
$$
a+bX = \log(\frac{P(X)}{1-P(X)})
$$
Cost function of the model is often the maximal likehood:
$$
l(a,b)=\prod_{y_i=1}P(x_i)\prod_{y_i=0}(1-P(x_i)).
$$
The goal is to find $a, b$ such that $l(a,b)$ is minimized.

\subsection{Gaussian Discriminant Analysis}

We only discuss Linear Discriminant Analysis for now, at the end we will get a touch on the quadratic case.

\subsubsection{Bayesian Distribution}
The basic idea is to use the Bayes Formula to compute the posterior probability using the prior probability. We are given data points $(x_1,\ldots, x_n)$. For each data point $x_i$ we also know its class $y_i = k$, where $k \in \{1,\ldots, m\}$ is the index of a class. We can know the prior probability by counting:
$$
\pi_k = P(Y = k).
$$
If we also know the pdf of the distribution of the data points within each class $k$, that is $f(X|Y=k)$, we can compute the posterior probability:
$$
P(Y=k|X=x) = \frac{\pi_kf(X=x|Y=k)}{\sum \pi_if(X=x|Y=i)}
$$
This conditional probability can be interpreted as the probability of the data point $x$ belonging to the class $k$. Then by comparing the probabilities varying $k$ of the same data point, we can choose the $k$ that correspond to the largest probability - that is our prediction of the class $x$ belongs to.

\subsubsection{Gaussian Discriminants}

We now carry out the computation under the assumption that $x\sim n(\mu_k,\sigma_k^2)$, that is 
$$
f(x|y=k) = \frac{1}{\sigma_k\sqrt{2\pi}}\exp(-\frac{(x-\mu_k)^2}{2\sigma_k^2})
$$
We want to make a further assumption:
$$
\sigma_1^2 = \ldots = \sigma_m^2=:\sigma^2
$$
Note that this assumption leads to the linearity of the decision boundary. By removing this assumption we may achieve a quadratic boundary at computational costs.

We can now write down the posterior probability:
\begin{equation}\label{GDA}
P_k(x) := P(Y=k|X=x) = \frac{\pi_k\exp(-\frac{(x-\mu_k)^2}{2\sigma^2})}{m(x)}
\end{equation}
We use $m(x)$ to denote the denominator, note that it is independent of $k$.

Taking the logarithm, we get
$$
\log P_k(x) = (\frac{\mu_k}{\sigma^2}x-(\frac{\mu_k}{2\sigma^2}-\log\pi_k))-(\frac{x^2}{2\sigma^2}+\log m(x))
$$
Note that the last two terms are independent of $k$. Therefore if we want to return the $k$ such that the $P_k$ is the largest, we only need to look at
$$
\delta_k(x) := \frac{\mu_k}{\sigma^2}x-(\frac{\mu_k}{2\sigma^2}-\log\pi_k)
$$
It is a linear function. And if we don't make the equal-variance assumption, then the last but one term must be included, and $\delta_k$ will be quadratic.
 
\subsubsection{Unbiased Estimators}
Finally, in order to compare the $\delta_k$s, we need to have unbiased estimators for $\pi_k$, $\mu_k$ and $\sigma^2$. We already know that $\pi_k = n_k/(\sum n_k)$ can be computed by getting the count ($n_k$) of the points that belonged to the $k$-th class . We can estimate the rest by 
\begin{equation}\label{GDA_MLE}
\mu_k = \frac{\sum_{y_i = k} x_i}{n_k} \qquad \sigma^2 = \frac{1}{n-m}\sum_{k = 1}^{m}\sum_{y_i = k}(x_i-\mu_k)^2.
\end{equation}


\subsection{Boostrap}

Boostrap is the name for sampling with replacement. It can create training set of desirable size. We can use Boostrap to estimate standard deviation and to reduce variance.

\subsubsection{Estimating the standard deviation}
\begin{enumerate}
\item Sample with replacement $n$ samples from the original data set.
\item Compute the std / median / mean (the quantity that you want to estimate) from the sample pile
\item Average among all sample piles.
\end{enumerate}

\subsubsection{Reducing Variance}
This is also called Boostrap Aggregation (Bagging) method. The basic reason we use here is if we take 
$z_1,\ldots,z_k\sim n(0,\sigma^2)$, then $\bar z \sim n(0,\sigma^2/n)$.
\begin{enumerate}
\item Boostrap and get $k$ training sets
\item train the model (often an inflexible one, such as a decision tree model) on each training sets and get $k$ models with function $f_1,\ldots, f_k$.
\item Average and get $\bar f$.
\end{enumerate}

\subsection{Random Forest}
Random Forest is basically a Bagging model, plus an important feature: Every time when we train the models, instead of using the full set of features, we randomly pick $m<p$ features from the set of features (typically $m = \sqrt{p}$).

If there is one significant feature in the set of features, then very likely that all bagged trees looking similar. Using Random Forest prevents that, and hence further reduce variance.

\subsubsection{Out of bag Error (OOB)}
\begin{enumerate}
\item Estimate test error on each model
\item Compute the mean test error on the data point $x_i$ for those models that does NOT contain $x_i$ in their training set.
\end{enumerate}

\subsection{Support Vector Machine}

\subsection{K-Means Clustering}
Unsupervised Learning. 

\subsubsection{Algorithm}
\begin{enumerate}
\item Randomly Assign each observation to a group (indexed by $1,\ldots, k$ for instance).
\item Compute the cluster centroid (mean of each feature within the cluster).
\item Reassign each observation to the cluster that has the closest centroid.
\item repeat the two steps above until convergence.
\end{enumerate}
Since the K-means can only converge to a local minimum, it is suggested that we repeat the steps k times and choose the "best" one.

Although we don't have $y_i$ so we can't compute the accuracy, but we can still measure which model is better by using the sum-of-square deviation:
$$
W(C_k):=\frac{1}{|C_k|}\sum_{i,i'\in C_k}\sum_{j}(x_{ij}-x_{i'j})^2=2\sum_{i\in C_k}\sum_{j}(x_{ij}-\bar x_{kj})^2
$$
where $i$ is the index for data points, and $j$ is the index for features. So $W(C_k)$ is the sum of Euclidean distance of the data points to the cluster centroid.

\subsubsection{How to Choose $k$}
We usually choose different $k$ to train and get different models. When $k$ increase, $W(C_k)$ is almost guaranteed to reduce. But the reducing rate will slow down when $k$ become larger (L-shape curve). We usually choose the turning point of the $L$ shape curve to be the ideal $k$ that balance the cost function and computer power.

\subsection{Hierarchical Clustering}
Unsupervised Learning. One big advantage is that we don't have to prefix $k$. One big disadvantage is that when we choose different linkage and distance, the result might vary greatly.
\subsubsection{Algorithm}
\begin{enumerate}
\item Select the type of Distance and the type of Linkage.
\item Treat each object as its own cluster. For $i = 0, \ldots, n-1$ do:\\ Compute ${n-i}\choose{2}$ pair-wise distance, fuse the closest two observations.
\item The process ends when we have only one cluster. We cut the tree off at the level of a desirable $k$ branches.
\end{enumerate}

\subsubsection{Linkages}
\begin{itemize}
\item Complete: Maximal distance between two points from the two clusters
\item Single: Minimal distance ...
\item Average: Mean distance ...
\item Centroid: Distance between two centroids ...
\end{itemize}

\subsection{Gaussian Mixture Model (EM Algorithm)}

This section is closely related to the Gaussian Discriminant Analysis section. Given a set of data points $(x_1,\ldots, x_n)$, and number of classes $k$. Note that we don't know the classes $y_i$ of each data point, therefore this is an unsupervised learning algorithm.

We want to classify the data points into $k$ classes, so that the distribution of data points within each class has a normal distribution. Namely, we assume 
$$
P(x_i|z_i=j) \sim n(\mu_j,\sigma_j)
$$
Note that the $z_i$ is the class of $x_i$, and we don't know $z_i$.

\subsubsection{EM algorithm}
EM stands for Expectation-Maximization. Initialize by randomly assign classes, then repeat until convergence:
\begin{itemize}
\item[Step E]: Given the current distributions, compute the posterior probability that the data point $x_i$ belongs to the $j$-th class:
$$
w_j^{(i)} = P(z_i = j| X = x_i, \pi_j, \mu_j, \sigma_j)
$$
as in (\ref{GDA}).

\item[Step M]: We have the most updated $z_i$, we can then update the parameters using the Maximal Likelihood Estimators of the current data as in (\ref{GDA_MLE}). The likelihood function is:
$$
l(\pi_i,\mu_i,\sigma_i) = \sum\log P(x_i, \pi_i,\mu_i,\sigma_i).
$$
\end{itemize}

\subsubsection{Relation to GDA}
We can see that Gaussian Discriminant Analysis is the process from Step M to Step E: we first use the current labeled data point to compute the MLE for $\pi, \mu, \sigma$, then when a new data point comes in, we can use Step E to compute for the probability of each class.

\subsection{Methods of Dimension Reduction}

\section{Pros and Cons List}
The general guideline for Machine Learning models is their flexibility.
\begin{itemize}
\item Flexible Models: Such as Boosting models. They tend to have {\em less bias, and more variance} on test sets. They fit better on training sets and may sometimes overfit. Not easy to interpret.
\item Inflexible Models: Such as Linear models. They tend to have {\em more bias, and less variance} on test sets. They usually have more rigid shape and easier to interpret. 
\end{itemize}

\subsection{Regressions}
\subsubsection{Linear Regression}

\begin{itemize}
\item Pros: 

\begin{enumerate}
\item Easy to understand;
\item Can do feature selection by looking at p-values of each coeffiecient
\item Fast / Computationally cheap
\item Low test variance and avoid overfitting (Inflexible)
\end{enumerate}

\item Cons:

\begin{enumerate}
\item Suffer from high leverage
\item For the best result, the variables are preferred to be numerical
\item Can't be used on Classification Problems
\item Suffer from multi-linearity among variables
\item Has an assumption on the true relationships (Linear, Quadratic...)
\item Does not accommodate for missing values.
\end{enumerate}

\end{itemize}

\subsubsection{Lasso VS Ridge}
Both requires scaling the parameters.
\begin{itemize}
\item Pros:

\begin{enumerate}
\item (Lasso) Can introduce sparsity into the coefficients. So if there is a subset of significant features, then it is a pro.
\item (Both) Reduce collinearity among the feature.
\end{enumerate}

\item Cons:

\begin{enumerate}
\item If all features are important, then maybe not as good as usual LR or Ridge (too automatics.)
\end{enumerate}

\end{itemize}

\subsubsection{Decision Trees}

\begin{itemize}
\item Pros: 

\begin{enumerate}
\item Easy to explain (can plot easily)
\item Handles categorical features.
\item Works well if the true decision boundary is parallel to feature axis.
\end{enumerate}

\item Cons:

\begin{enumerate}
\item (Due to flexibility) may easily overfit.
\item Do not work well is the true decision boundary is not parallel.
\item (Non-robust) small change can lead to a big chance in the result.
\end{enumerate}

\end{itemize}

\subsubsection{Random Forest}

\begin{itemize}
\item Pros: 
\begin{enumerate}
\item Reduce Variance by averaging over multiple models.
\item Can use OOB estimates for the test errors
\item Avoid highly correlated features
\end{enumerate}

\item Cons:

\begin{enumerate}
\item Not easy to explain / interpreted visually
\item May overfit
\item Learn slowly if not pruned suitably.
\end{enumerate}

\end{itemize}

\subsubsection{Boosted Trees}

\begin{itemize}
\item Pros: 

\begin{enumerate}
\item Using smaller trees enhance model interpretability (stumps (1-level trees) gives an additive model)
\end{enumerate}

\item Cons:

\begin{enumerate}
\item
\end{enumerate}

\end{itemize}


\subsection{Classifications}

\subsubsection{Naive Bayes}

\begin{itemize}
\item Pros: 

\begin{enumerate}
\item Simple to implement
\item Computationally fast
\item Works well in higher dimensions
\end{enumerate}

\item Cons:

\begin{enumerate}
\item Highly replying on the variables being independent
\item Zero Frequency (for missing data in certain category)
\item not so accurate
\end{enumerate}

\end{itemize}

\subsubsection{Logistic Regression}

\begin{itemize}
\item Pros: 

\begin{enumerate}
\item (Due to Inflexibility) Low variance
\item (Soft Assign) Gives probability for outcomes
\item Work well with different boundary shapes
\item Can use L1/L2 regularization to avoid overfitting
\end{enumerate}

\item Cons:

\begin{enumerate}
\item High bias
\end{enumerate}

\end{itemize}

\subsubsection{Support Vector Machines}

\begin{itemize}
\item Pros: 

\begin{enumerate}
\item Perform well to non-linear boundary using Kernal Trick
\item Handles High dimensional data
\end{enumerate}

\item Cons:

\begin{enumerate}
\item Need to use a correct kernel
\end{enumerate}

\end{itemize}

\subsubsection{Gaussian Discriminant Analysis}

\begin{itemize}
\item Pros: 

\begin{enumerate}
\item Multi-class prediction
\item When data size is large, well performed in accuracy and fast
\item require less data to train well. (similar to Naive Bayes).
\end{enumerate}

\item Cons:

\begin{enumerate}
\item Assume normal distribution
\item Not so robust comparing to Logistic regression
\item No good for few-categorical variables
\item Suffer collinearity.
\end{enumerate}

\end{itemize}

\subsection{Unsupervised Learning}

\subsubsection{K-means Clustering}

\begin{itemize}
\item Pros: 

\begin{enumerate}
\item Simple / Fast for large data sets
\item Easy to interpret
\item Accuracy
\item Spherical Clusters (can be a con too)
\end{enumerate}

\item Cons:

\begin{enumerate}
\item Need to choose K
\item Local method - may converge to different clusters
\item Clusters are of equal sizes
\item Sensitive to scales
\item Only for Numerical data
\end{enumerate}

\end{itemize}

\subsubsection{Gaussian Mixture Model}

\begin{itemize}
\item Pros: (Comparing to K-means)

\begin{enumerate}
\item Doesn't depend on L-2 norm
\item Soft Assign, give estimate to probabilities.
\end{enumerate}

\item Cons:

\begin{enumerate}
\item Need to assume the data are normally distributed in each class.
\end{enumerate}

\end{itemize}
%-------------------------------------------------------------------------------------------------------------------------------
%------------------------------------------------Recommendation System--------------------------------------------
%-------------------------------------------------------------------------------------------------------------------------------

\section{Recommendation System}

\subsection{Content Based Recommendation}

\subsection{Collaborative Filtering}
%-------------------------------------------------------------------------------------------------------------------------------
%------------------------------------------------------Deep Learning-----------------------------------------------------
%-------------------------------------------------------------------------------------------------------------------------------

\section{Deep Learning}

%-------------------------------------------------------------------------------------------------------------------------------
%------------------------------------------------------Coding----------------------------------------------------------------
%-------------------------------------------------------------------------------------------------------------------------------

\section{Coding}


\begin{thebibliography}{}
\bibitem[SI]{SI}
G.~Casella, R.~L.~Berger,
\newblock Statistics Inferences
\newblock (2001) {\em Duxbury Press.} ISBN 0-534-24312-6.

\bibitem[ISLR]{ISLR}
G.~James, D.~Witten, T.~Hastie, R.~Tibshirani,
\newblock An Introduction to Statistics Learning with Applications in R
\newblock (2013) {\em Springer} ISBN 1461471370.

\end{thebibliography}
\end{document}




